{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:22.045930Z","iopub.execute_input":"2023-07-16T11:08:22.046358Z","iopub.status.idle":"2023-07-16T11:08:35.799402Z","shell.execute_reply.started":"2023-07-16T11:08:22.046322Z","shell.execute_reply":"2023-07-16T11:08:35.797986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport albumentations as A\nimport torchinfo\nimport timm\n\nfrom transformers import SegformerModel, SegformerConfig, SegformerForSemanticSegmentation\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-16T11:08:35.802338Z","iopub.execute_input":"2023-07-16T11:08:35.802763Z","iopub.status.idle":"2023-07-16T11:08:50.386127Z","shell.execute_reply.started":"2023-07-16T11:08:35.802711Z","shell.execute_reply":"2023-07-16T11:08:50.385179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else 'cpu'\nargs = {\n    \"fold\" : 0,\n    \"epoches\" : 20,\n    \"batch_size\" : 2,\n    \"start_lr\" : 4e-5,\n    \"image_size\" : 720\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.387572Z","iopub.execute_input":"2023-07-16T11:08:50.387929Z","iopub.status.idle":"2023-07-16T11:08:50.424817Z","shell.execute_reply.started":"2023-07-16T11:08:50.387894Z","shell.execute_reply":"2023-07-16T11:08:50.422967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hubmap-organ-segmentation/train.csv')\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.427895Z","iopub.execute_input":"2023-07-16T11:08:50.428516Z","iopub.status.idle":"2023-07-16T11:08:50.810981Z","shell.execute_reply.started":"2023-07-16T11:08:50.428478Z","shell.execute_reply":"2023-07-16T11:08:50.809932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=5)\ndf['fold'] = -1\nfor idx, (train_idx, valid_idx) in enumerate(kf.split(X=df)):\n    df.loc[valid_idx, 'fold'] = idx","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.812845Z","iopub.execute_input":"2023-07-16T11:08:50.813344Z","iopub.status.idle":"2023-07-16T11:08:50.824280Z","shell.execute_reply.started":"2023-07-16T11:08:50.813302Z","shell.execute_reply":"2023-07-16T11:08:50.822931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['fold'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.825560Z","iopub.execute_input":"2023-07-16T11:08:50.827773Z","iopub.status.idle":"2023-07-16T11:08:50.841509Z","shell.execute_reply.started":"2023-07-16T11:08:50.827738Z","shell.execute_reply":"2023-07-16T11:08:50.840594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_augment = A.Compose([\n    A.RandomCrop(512, 512, p=0.3),\n    A.Resize(args['image_size'], args['image_size'], p = 1),\n    A.HorizontalFlip(p=0.3),\n    A.VerticalFlip(p=0.3),\n    A.RandomRotate90(p=0.3),\n    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n    A.OneOf([\n            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, brightness_by_max=True, p=0.3)], p=0.5)\n])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.844209Z","iopub.execute_input":"2023-07-16T11:08:50.845331Z","iopub.status.idle":"2023-07-16T11:08:50.853441Z","shell.execute_reply.started":"2023-07-16T11:08:50.845299Z","shell.execute_reply":"2023-07-16T11:08:50.852222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class segDataset(Dataset):   \n    def __init__(self, df, augment):\n        self.df = df              \n        self.augment = augment    \n\n    def __len__(self): \n        return len(self.df)\n\n    def __getitem__(self, index): \n        d = self.df.iloc[index]\n        id = d['id']\n        height = d['img_height']\n        width = d['img_width']\n\n        image = cv2.imread(f'/kaggle/input/hubmap-data/train_image/{id}.png')                       \n        mask  = cv2.imread(f'/kaggle/input/hubmap-data/train_mask/{id}.png', cv2.IMREAD_GRAYSCALE)\n        \n        if self.augment is not None:\n            aug = self.augment(image= image, mask=mask)\n            image = aug['image']\n            mask  = aug['mask']\n        mask = np.stack([mask], axis=0)\n        image = image / 255.  \n        mask  = mask  / 255. \n\n        out = {}\n        out['image'] = torch.tensor(image).permute(2,0,1).float() # h, w, c -> c, h, w\n        out['mask']  = torch.tensor(mask>0.5).float()\n        \n        return out\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.866279Z","iopub.execute_input":"2023-07-16T11:08:50.866847Z","iopub.status.idle":"2023-07-16T11:08:50.879126Z","shell.execute_reply.started":"2023-07-16T11:08:50.866798Z","shell.execute_reply":"2023-07-16T11:08:50.877987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#albumentations -> channel : 3 or 0","metadata":{}},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# class UNetEncoder(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.maxpool = nn.MaxPool2d(2)\n#         self.block1 = nn.Sequential(\n#             nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = 64, out_channels= 64, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block2 = nn.Sequential(\n#             nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = 128, out_channels= 128, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block3 = nn.Sequential(\n#             nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block4 = nn.Sequential(\n#             nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n\n#     def forward(self, batch):\n#         x = batch['image']\n#         x = self.block1(x)\n#         x = self.maxpool(x)\n#         x = self.block2(x)\n#         x = self.maxpool(x)\n#         x = self.block3(x)\n#         x = self.maxpool(x)\n#         x = self.block4(x)\n\n#         return x\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.884221Z","iopub.execute_input":"2023-07-16T11:08:50.884540Z","iopub.status.idle":"2023-07-16T11:08:50.897135Z","shell.execute_reply.started":"2023-07-16T11:08:50.884510Z","shell.execute_reply":"2023-07-16T11:08:50.896165Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class UNetDecoder(nn.Module):\n#     def __init__(self, dim):\n#         super().__init__()\n#         self.upsample = nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners=True)\n#         self.block1 = nn.Sequential(\n#             nn.Conv2d(in_channels = dim, out_channels = dim // 2, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = dim // 2 , out_channels = dim // 2, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block2 = nn.Sequential(\n#             nn.Conv2d(in_channels = dim // 2, out_channels= dim // 4, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = dim // 4, out_channels= dim // 4, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block3 = nn.Sequential(\n#             nn.Conv2d(in_channels = dim // 4, out_channels = dim // 8, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = dim // 8, out_channels= dim // 8, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.last_conv = nn.Conv2d(in_channels = dim // 8, out_channels = 1, kernel_size = 1)\n#     def forward(self, x):\n#     #TODO Skip Connection\n#         x = self.upsample(x)\n#         x = self.block1(x)\n#         x = self.upsample(x)\n#         x = self.block2(x)\n#         x = self.upsample(x)\n#         x = self.block3(x)\n#         x = self.last_conv(x)\n#         x = F.interpolate(x, size=(720,720))\n#         return x","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:50.898501Z","iopub.execute_input":"2023-07-16T11:08:50.899270Z","iopub.status.idle":"2023-07-16T11:08:50.912357Z","shell.execute_reply.started":"2023-07-16T11:08:50.899237Z","shell.execute_reply":"2023-07-16T11:08:50.911518Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Net(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.encoder = timm.create_model('tf_efficientnet_b6', \n#                                          pretrained = True, \n#                                          num_classes = 0,   \n#                                          global_pool = '') \n        \n#         dim = self.encoder.conv_head.out_channels # effnet_b4 = 1792\n#         self.decoder = UNetDecoder(dim = dim)\n\n#     def forward(self, batch):\n#         x = self.encoder(batch['image'])\n#         logit = self.decoder(x)\n        \n#         out = {}\n        \n#         if self.training :\n#             out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n\n#         else :\n#             out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n#             out['probability'] = torch.sigmoid(logit)\n        \n#         return out","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:51.497408Z","iopub.execute_input":"2023-07-16T11:08:51.498249Z","iopub.status.idle":"2023-07-16T11:08:51.507600Z","shell.execute_reply.started":"2023-07-16T11:08:51.498215Z","shell.execute_reply":"2023-07-16T11:08:51.506291Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = Net().to(device)\n_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b4-finetuned-ade-512-512\",\n                                                        num_labels = 1,\n                                                        ignore_mismatched_sizes=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:08:51.510685Z","iopub.execute_input":"2023-07-16T11:08:51.511081Z","iopub.status.idle":"2023-07-16T11:09:03.708366Z","shell.execute_reply.started":"2023-07-16T11:08:51.511048Z","shell.execute_reply":"2023-07-16T11:09:03.707345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, model,image_size):\n        super().__init__()\n        self.model = model\n        self.image_size = image_size\n    \n    def forward(self, batch):\n        logit = self.model(batch['image']).logits\n        logit = F.interpolate(logit, (720, 720))\n        out = {}\n        \n        if self.training :\n            out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n\n        else :\n            out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n            out['probability'] = torch.sigmoid(logit)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.709752Z","iopub.execute_input":"2023-07-16T11:09:03.710192Z","iopub.status.idle":"2023-07-16T11:09:03.720875Z","shell.execute_reply.started":"2023-07-16T11:09:03.710153Z","shell.execute_reply":"2023-07-16T11:09:03.719937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df['fold']!=args['fold']]\nvalid_df = df[df['fold']==args['fold']]","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.722358Z","iopub.execute_input":"2023-07-16T11:09:03.722737Z","iopub.status.idle":"2023-07-16T11:09:03.733226Z","shell.execute_reply.started":"2023-07-16T11:09:03.722707Z","shell.execute_reply":"2023-07-16T11:09:03.732249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_df), len(valid_df))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.734385Z","iopub.execute_input":"2023-07-16T11:09:03.735040Z","iopub.status.idle":"2023-07-16T11:09:03.748190Z","shell.execute_reply.started":"2023-07-16T11:09:03.734992Z","shell.execute_reply":"2023-07-16T11:09:03.747204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" model = Net(model = _model)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.749395Z","iopub.execute_input":"2023-07-16T11:09:03.750381Z","iopub.status.idle":"2023-07-16T11:09:03.759145Z","shell.execute_reply.started":"2023-07-16T11:09:03.750345Z","shell.execute_reply":"2023-07-16T11:09:03.757946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = segDataset(df = train_df, augment = train_augment)\n\ntrain_dl = DataLoader(train_ds,\n                batch_size = args['batch_size'],\n                shuffle = True,\n                pin_memory = True,\n                drop_last = False\n                     )\n\nvalid_ds = segDataset(df = valid_df, augment = None)\n\nvalid_dl = DataLoader(valid_ds,\n                batch_size = args['batch_size'],\n                shuffle = False,\n                pin_memory = True,\n                drop_last = False\n                )\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.762493Z","iopub.execute_input":"2023-07-16T11:09:03.763527Z","iopub.status.idle":"2023-07-16T11:09:03.771250Z","shell.execute_reply.started":"2023-07-16T11:09:03.763480Z","shell.execute_reply":"2023-07-16T11:09:03.770119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr = args['start_lr'])\n#scheduler =","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.772788Z","iopub.execute_input":"2023-07-16T11:09:03.773144Z","iopub.status.idle":"2023-07-16T11:09:03.785920Z","shell.execute_reply.started":"2023-07-16T11:09:03.773114Z","shell.execute_reply":"2023-07-16T11:09:03.784898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_dice_score(probability, mask):\n    N = len(probability)\n    p = probability.reshape(N,-1)\n    t = mask.reshape(N,-1)\n    p = p>0.5\n    t = t>0.5\n    uion = p.sum(-1) + t.sum(-1)\n    overlap = (p*t).sum(-1)\n    dice = 2*overlap/(uion+0.0001)\n    return dice","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.787291Z","iopub.execute_input":"2023-07-16T11:09:03.787684Z","iopub.status.idle":"2023-07-16T11:09:03.796917Z","shell.execute_reply.started":"2023-07-16T11:09:03.787653Z","shell.execute_reply":"2023-07-16T11:09:03.795796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.798128Z","iopub.execute_input":"2023-07-16T11:09:03.798432Z","iopub.status.idle":"2023-07-16T11:09:03.807762Z","shell.execute_reply.started":"2023-07-16T11:09:03.798409Z","shell.execute_reply":"2023-07-16T11:09:03.806845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model, valid_dl):\n    logits = []\n    losses = []\n    masks  = []\n    for batch in tqdm(valid_dl, total=len(valid_dl)):\n        batch['image'] = batch['image'].to(device)\n        batch['mask']  = batch['mask'].to(device)\n\n        model.eval()\n        with torch.no_grad():\n            out = model(batch)\n        loss = out['bce_loss'].mean()\n        logit = out['probability']\n        \n        logits.append(logit.detach().cpu().numpy())\n        losses.append(loss.detach().cpu().numpy())\n        masks.append(batch['mask'].detach().cpu().numpy())\n    \n    logits = np.concatenate(logits)\n    masks = np.concatenate(masks)\n    \n    score = compute_dice_score(logits, masks).mean()\n    losses = np.asarray(losses).mean()\n    \n    return score, losses\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.809269Z","iopub.execute_input":"2023-07-16T11:09:03.809664Z","iopub.status.idle":"2023-07-16T11:09:03.819743Z","shell.execute_reply.started":"2023-07-16T11:09:03.809635Z","shell.execute_reply":"2023-07-16T11:09:03.818692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = '/kaggle/working/model/'\nos.makedirs(save_path, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.821190Z","iopub.execute_input":"2023-07-16T11:09:03.821782Z","iopub.status.idle":"2023-07-16T11:09:03.830452Z","shell.execute_reply.started":"2023-07-16T11:09:03.821751Z","shell.execute_reply":"2023-07-16T11:09:03.829551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_score = 0\nfor ep in tqdm(range(args['epoches'])):\n    losses = []\n    for batch in tqdm(train_dl, total = len(train_dl)):\n        model.train()\n        with torch.cuda.amp.autocast():\n            batch['image'] = batch['image'].to(device)\n            batch['mask']  = batch['mask'].to(device)\n            out = model(batch)\n            loss = out['bce_loss'].mean()\n\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        #scheduler.step()\n        losses.append(loss.detach().cpu().numpy())\n        \n    train_loss = np.asarray(losses).mean()\n    score, valid_loss = valid(model, valid_dl)\n    \n    if best_score < score :\n        torch.save(model.state_dict(), save_path + f'ep_{ep}_unet_model.pt')\n        best_score = score\n    print(f'ep_{ep} train_loss : {train_loss}, valid_loss : {valid_loss}, dice_score : {score}')\n    #torch.save(optimizer.state_dict(), save_path + f'ep_{ep}_unet_optimizer.pt')\n    #torch.save(scheduler.state_dict(), save_path + f'ep_{ep}_unet_scheduler.pt')\nprint('train finished')","metadata":{"execution":{"iopub.status.busy":"2023-07-16T11:09:03.832072Z","iopub.execute_input":"2023-07-16T11:09:03.832743Z"},"trusted":true},"execution_count":null,"outputs":[]}]}