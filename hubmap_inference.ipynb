{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport glob\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport torch.cuda.amp as amp\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport gc\nimport json\n\nfrom matplotlib import pyplot as plt\nfrom tqdm.notebook import tqdm\n\nsys.path.append('/kaggle/input/timm-clone/pytorch-image-models/')\ndevice = \"cuda\" if torch.cuda.is_available() else 'cpu'\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2023-07-20T03:23:27.299324Z","iopub.execute_input":"2023-07-20T03:23:27.299606Z","iopub.status.idle":"2023-07-20T03:23:33.452272Z","shell.execute_reply.started":"2023-07-20T03:23:27.299580Z","shell.execute_reply":"2023-07-20T03:23:33.451268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q /kaggle/input/tlvmc-src/transformers-4.29.2-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-07-20T03:23:33.454165Z","iopub.execute_input":"2023-07-20T03:23:33.454734Z","iopub.status.idle":"2023-07-20T03:24:14.774833Z","shell.execute_reply.started":"2023-07-20T03:23:33.454689Z","shell.execute_reply":"2023-07-20T03:24:14.773660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#-- configure ---------------------------------------------\n\norgan_threshold = {\n    'Hubmap': {\n        'kidney'        : 0.40,\n        'prostate'      : 0.40,\n        'largeintestine': 0.40,\n        'spleen'        : 0.40,\n        'lung'          : 0.10,\n    },\n    'HPA': {\n        'kidney'        : 0.50,\n        'prostate'      : 0.50,\n        'largeintestine': 0.50,\n        'spleen'        : 0.50,\n        'lung'          : 0.10,\n    },\n}\n\nargs = {\n    'batch_size' : 1,\n    'image_size' : 768\n}\n\nsubmit_type = 'submission'#'cv'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-20T03:24:14.776966Z","iopub.execute_input":"2023-07-20T03:24:14.777382Z","iopub.status.idle":"2023-07-20T03:24:14.785583Z","shell.execute_reply.started":"2023-07-20T03:24:14.777338Z","shell.execute_reply":"2023-07-20T03:24:14.783876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# class UNetDecoder(nn.Module):\n#     def __init__(self, dim):\n#         super().__init__()\n#         self.upsample = nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners=True)\n#         self.block1 = nn.Sequential(\n#             nn.Conv2d(in_channels = dim, out_channels = dim // 2, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = dim // 2 , out_channels = dim // 2, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block2 = nn.Sequential(\n#             nn.Conv2d(in_channels = dim // 2, out_channels= dim // 4, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = dim // 4, out_channels= dim // 4, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.block3 = nn.Sequential(\n#             nn.Conv2d(in_channels = dim // 4, out_channels = dim // 8, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels = dim // 8, out_channels= dim // 8, kernel_size = 3, padding = \"same\"),\n#             nn.ReLU()\n#         )\n#         self.last_conv = nn.Conv2d(in_channels = dim // 8, out_channels = 1, kernel_size = 1)\n#     def forward(self, x):\n#     #TODO Skip Connection\n#         x = self.upsample(x)\n#         x = self.block1(x)\n#         x = self.upsample(x)\n#         x = self.block2(x)\n#         x = self.upsample(x)\n#         x = self.block3(x)\n#         x = self.last_conv(x)\n#         #x = F.interpolate(x, size=(720,720))\n#         return x","metadata":{"execution":{"iopub.status.busy":"2023-07-20T03:24:14.788623Z","iopub.execute_input":"2023-07-20T03:24:14.789001Z","iopub.status.idle":"2023-07-20T03:24:14.803161Z","shell.execute_reply.started":"2023-07-20T03:24:14.788968Z","shell.execute_reply":"2023-07-20T03:24:14.802069Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Net(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.encoder = timm.create_model('tf_efficientnet_b6',\n#                                          pretrained = False, \n#                                          num_classes = 0,   \n#                                          global_pool = '')  \n        \n#         dim = self.encoder.conv_head.out_channels # effnet_b4 = 1792\n#         self.decoder = UNetDecoder(dim = dim)\n\n#     def forward(self, batch):\n#         x = self.encoder(batch['image'])\n#         logit = self.decoder(x)\n        \n#         out = {}\n        \n#         if self.training :\n#             out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n\n#         else :\n#             #out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n#             out['probability'] = torch.sigmoid(logit)\n        \n#         return out","metadata":{"execution":{"iopub.status.busy":"2023-07-20T03:24:14.804535Z","iopub.execute_input":"2023-07-20T03:24:14.805055Z","iopub.status.idle":"2023-07-20T03:24:14.818465Z","shell.execute_reply.started":"2023-07-20T03:24:14.805023Z","shell.execute_reply":"2023-07-20T03:24:14.817446Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, model, image_size):\n        super().__init__()\n        self.model = model\n        self.image_size = image_size\n    def forward(self, batch):\n        logit = self.model(batch['image']).logits\n        logit = F.interpolate(logit, (self.image_size, self.image_size))\n        out = {}\n        \n        if self.training :\n            out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n\n        else :\n            #out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n            out['probability'] = torch.sigmoid(logit)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:16.742737Z","iopub.execute_input":"2023-07-20T04:00:16.743807Z","iopub.status.idle":"2023-07-20T04:00:16.751589Z","shell.execute_reply.started":"2023-07-20T04:00:16.743762Z","shell.execute_reply":"2023-07-20T04:00:16.750047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if submit_type == 'cv':\n    valid_file = '../input/hubmap-organ-segmentation/train.csv'\n\nif submit_type == 'submission':\n    valid_file = '../input/hubmap-organ-segmentation/test.csv'\n\nvalid_df = pd.read_csv(valid_file)\nvalid_df  = valid_df.sort_values('id')\nvalid_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:17.121612Z","iopub.execute_input":"2023-07-20T04:00:17.121988Z","iopub.status.idle":"2023-07-20T04:00:17.139848Z","shell.execute_reply.started":"2023-07-20T04:00:17.121957Z","shell.execute_reply":"2023-07-20T04:00:17.138846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_local_validation():\n    submit_df = pd.read_csv('./submission.csv').fillna('')\n    submit_df = submit_df.sort_values('id')\n    truth_df  = valid_df.sort_values('id')\n    \n    lb_score = []\n    num = len(submit_df)\n    for i in range(num):\n        t_df = truth_df.iloc[i]\n        p_df = submit_df.iloc[i]\n        t = rle_decode(t_df.rle, t_df.img_height, t_df.img_width, 1)\n        p = rle_decode(p_df.rle, t_df.img_height, t_df.img_width, 1)\n        \n        dice = 2*(t*p).sum()/(p.sum()+t.sum())\n        lb_score.append(dice)\n        \n    truth_df.loc[:,'lb_score']=lb_score\n    for organ in ['all', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n        if organ != 'all':\n            d = truth_df[truth_df.organ == organ]\n        else:\n            d = truth_df\n        print('\\t%f\\t%s\\t%f' % (len(d) / len(truth_df), organ, d.lb_score.mean()))","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:17.275519Z","iopub.execute_input":"2023-07-20T04:00:17.275817Z","iopub.status.idle":"2023-07-20T04:00:17.286551Z","shell.execute_reply.started":"2023-07-20T04:00:17.275790Z","shell.execute_reply":"2023-07-20T04:00:17.285629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class segDataset(Dataset):   \n    def __init__(self, df, augment, submit_type):\n        self.df = df              \n        self.augment = augment    \n        self.submit_type = submit_type\n\n    def __len__(self): \n        return len(self.df)\n\n    def __getitem__(self, index): \n        d = self.df.iloc[index]\n        id = d['id']\n        height = d['img_height']\n        width = d['img_width']\n        if self.submit_type == 'cv':\n            tiff_dir   = '../input/hubmap-organ-segmentation/train_images'\n            \n        if self.submit_type == 'submission':\n            tiff_dir   = '../input/hubmap-organ-segmentation/test_images'\n         \n        image = cv2.imread(f'{tiff_dir}/{id}.tiff') \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, dsize=(args['image_size'], args['image_size']))\n        image = image / 255.  \n\n        out = {}\n        out['id']    = d['id']\n        out['image'] = torch.tensor(image).permute(2,0,1).float() # h, w, c -> c, h, w\n        out['data_source'] = d['data_source']\n        out['organ']  = d['organ']\n        out['height'] = d['img_height']\n        out['width']  = d['img_width']\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:17.568493Z","iopub.execute_input":"2023-07-20T04:00:17.569115Z","iopub.status.idle":"2023-07-20T04:00:17.579732Z","shell.execute_reply.started":"2023-07-20T04:00:17.569076Z","shell.execute_reply":"2023-07-20T04:00:17.578664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_ds = segDataset(df = valid_df, augment = None, submit_type = submit_type)\n\nvalid_dl = DataLoader(valid_ds,\n                batch_size = args['batch_size'],\n                shuffle = False,\n                pin_memory = True,\n                drop_last = False\n                )","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:17.680743Z","iopub.execute_input":"2023-07-20T04:00:17.681353Z","iopub.status.idle":"2023-07-20T04:00:17.686981Z","shell.execute_reply.started":"2023-07-20T04:00:17.681315Z","shell.execute_reply":"2023-07-20T04:00:17.685805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from transformers import SegformerForSemanticSegmentation","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:17.976147Z","iopub.execute_input":"2023-07-20T04:00:17.976487Z","iopub.status.idle":"2023-07-20T04:00:17.980720Z","shell.execute_reply.started":"2023-07-20T04:00:17.976458Z","shell.execute_reply":"2023-07-20T04:00:17.979814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_model = SegformerForSemanticSegmentation.from_pretrained(\"/kaggle/input/d/methyl/hubmap-src/segformer-b4-finetuned-ade-512-512\",\n                                                        num_labels = 1,\n                                                        ignore_mismatched_sizes=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:18.108654Z","iopub.execute_input":"2023-07-20T04:00:18.109284Z","iopub.status.idle":"2023-07-20T04:00:19.809671Z","shell.execute_reply.started":"2023-07-20T04:00:18.109251Z","shell.execute_reply":"2023-07-20T04:00:19.808586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net(_model)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:19.811728Z","iopub.execute_input":"2023-07-20T04:00:19.812353Z","iopub.status.idle":"2023-07-20T04:00:19.818488Z","shell.execute_reply.started":"2023-07-20T04:00:19.812316Z","shell.execute_reply":"2023-07-20T04:00:19.816057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = [\n    '/kaggle/input/d/hubmap-src/ep_19_segformer_model.pt'\n]","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:19.820023Z","iopub.execute_input":"2023-07-20T04:00:19.820444Z","iopub.status.idle":"2023-07-20T04:00:19.837618Z","shell.execute_reply.started":"2023-07-20T04:00:19.820410Z","shell.execute_reply":"2023-07-20T04:00:19.836643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(len(model_path)):\n    model.load_state_dict(torch.load(model_path[i]))\n    model.eval()\n    model.to(device)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:19.840235Z","iopub.execute_input":"2023-07-20T04:00:19.840823Z","iopub.status.idle":"2023-07-20T04:00:20.201577Z","shell.execute_reply.started":"2023-07-20T04:00:19.840790Z","shell.execute_reply":"2023-07-20T04:00:20.200588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(rle, width, height, fill=1, dtype=np.float32):\n    s = rle.split()\n    start  = np.asarray(s[0::2], dtype=int)-1\n    length = np.asarray(s[1::2], dtype=int)\n    end = start + length\n    image = np.zeros(height * width, dtype=dtype)\n    for s, e in zip(start, end):\n        image[s:e] = fill\n    image = image.reshape(height, width) #.T\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:20.203234Z","iopub.execute_input":"2023-07-20T04:00:20.203580Z","iopub.status.idle":"2023-07-20T04:00:20.214012Z","shell.execute_reply.started":"2023-07-20T04:00:20.203547Z","shell.execute_reply":"2023-07-20T04:00:20.212890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor i,d in tqdm(enumerate(valid_dl), total=len(valid_dl)):    \n    cnt  = 0\n    prob = 0\n    TTA  = False \n    with torch.no_grad():\n        with amp.autocast(enabled = True):\n            d['image'] = d['image'].to(device)\n            \n            for i in range(len(models)):\n                cnt += 1\n                output = models[i](d)\n\n                prob += \\\n                F.interpolate(output['probability'], size=(d['height'], d['width']),\n                              mode='bilinear',align_corners=False, antialias=True)\n                \n                # if TTA == True:\n                #    d['image'] = torch.fliplr(d['image'])\n                #    output = models[i](d)\n                #    cnt += 1\n                #    prob += \\\n                #    F.interpolate(output['probability'], size=(d['height'], d['width']),\n                #    mode='bilinear',align_corners=False, antialias=True)\n                \n            prob /= cnt\n    \n    prob = prob.detach().cpu().numpy() > organ_threshold[d['data_source'][0]][d['organ'][0]]\n    rle  = rle_encode(prob.T)\n    results.append({'id':d['id'].detach().cpu().numpy()[0], 'rle':rle})\n    \nsubmit_df = pd.DataFrame(results)\nsubmit_df.to_csv('submission.csv',index=False)\n\nsubmit_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:20.215358Z","iopub.execute_input":"2023-07-20T04:00:20.215777Z","iopub.status.idle":"2023-07-20T04:00:20.518835Z","shell.execute_reply.started":"2023-07-20T04:00:20.215744Z","shell.execute_reply":"2023-07-20T04:00:20.517784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Local Validation","metadata":{}},{"cell_type":"code","source":"def do_local_validation():\n    submit_df = pd.read_csv('./submission.csv').fillna('')\n    submit_df = submit_df.sort_values('id')\n    truth_df  = valid_df.sort_values('id')\n    \n    lb_score = []\n    num = len(submit_df)\n    for i in tqdm(range(num)):\n        t_df = truth_df.iloc[i]\n        p_df = submit_df.iloc[i]\n        t = rle_decode(t_df.rle, t_df.img_height, t_df.img_width, 1)\n        p = rle_decode(p_df.rle, t_df.img_height, t_df.img_width, 1)\n\n        dice = 2*(t*p).sum()/(p.sum()+t.sum())\n        lb_score.append(dice)\n    \n    truth_df.loc[:,'lb_score']=lb_score\n    for organ in ['all', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n        if organ != 'all':\n            d = truth_df[truth_df.organ == organ]\n        else:\n            d = truth_df\n        print('\\t%f\\t%s\\t%f' % (len(d) / len(truth_df), organ, d.lb_score.mean()))\n    \n    return t, p","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:20.520577Z","iopub.execute_input":"2023-07-20T04:00:20.520950Z","iopub.status.idle":"2023-07-20T04:00:20.531909Z","shell.execute_reply.started":"2023-07-20T04:00:20.520916Z","shell.execute_reply":"2023-07-20T04:00:20.530774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if submit_type == 'cv':\n    t, p = do_local_validation()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:00:20.534485Z","iopub.execute_input":"2023-07-20T04:00:20.534820Z","iopub.status.idle":"2023-07-20T04:00:20.544397Z","shell.execute_reply.started":"2023-07-20T04:00:20.534789Z","shell.execute_reply":"2023-07-20T04:00:20.543515Z"},"trusted":true},"execution_count":null,"outputs":[]}]}